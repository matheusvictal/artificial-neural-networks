{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Neural Networks\n",
    "\n",
    "### Brief historical context\n",
    "\n",
    "* 1958: Frank Rosenblatt proposes the perceptron as a bioinspired [conexionist](https://en.wikipedia.org/wiki/Connectionism) model. Neural networks are considered conexionist models because they are inspired by biological neurons, which represent information by a network of processing units and learning by the force of its conections;\n",
    "\n",
    "* 1969: Minsky e Papert (MIT) present training imitations for the original perceptron;\n",
    "\n",
    "* 1970-2010 Neural Networks winter: artificial inteligence research was much more focused in specialist models with theoretical basement and mathematical guarantees, like SVMs;\n",
    "\n",
    "* But with the disponibilization of enourmous density of data for training and the use of GPUs for parallel processing, neural networks and deep learning skyrocketed in research circles. Neural Networks were now capable of obtaining models with less and less error, resulting in a new spring of exitement on the field.\n",
    "\n",
    "\n",
    "### Machine Learning (ML) vs Deep Learning (DL)\n",
    "\n",
    "Machine Learning is a general field that includes Deep Learning. In ML, algorithms learn a function $f$ from a space of possible functions and a set of training data. \"Shallow\" methods infer a single function $f$ that relates the input with the output of the model. \"Deep\" methods ae organized in a set of hierarchical steps that feed information from one to another with composed functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors:\n",
    "\n",
    "Tensors are generalized vector structures with common use in neural networks applications. Pytorch is a machine learning framework that uses the Torch library to create deep learning models, specially neural networks and the basic data structure for the pytorch paradigm is the Tensor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic usage:\n",
    "* Generation;\n",
    "* Size;\n",
    "* Reshaping;\n",
    "* Idexing and slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " tensor([[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generation\n",
    "A = torch.arange(1,10)\n",
    "B = torch.ones([2,5])\n",
    "\n",
    "A,B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([9]), 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size\n",
    "A.shape, B.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshaping\n",
    "A.reshape([3,3])\n",
    "\n",
    "# Obs.: this is not an inplace operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing and slicing\n",
    "A[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[:-3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic operations and functions:\n",
    "* Unary operations;\n",
    "* Binary element by element operations;\n",
    "* Concatenation;\n",
    "* Broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.arange(1,10, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.6931, 1.0986, 1.3863, 1.6094, 1.7918, 1.9459, 2.0794, 2.1972])\n",
      "tensor([2.7183e+00, 7.3891e+00, 2.0086e+01, 5.4598e+01, 1.4841e+02, 4.0343e+02,\n",
      "        1.0966e+03, 2.9810e+03, 8.1031e+03])\n"
     ]
    }
   ],
   "source": [
    "# Unary operations\n",
    "print(torch.log(C))\n",
    "print(torch.exp(C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 3., 3., 3., 3., 3., 3., 3., 3.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = torch.ones(9)*3\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.]),\n",
       " tensor([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.]),\n",
       " tensor([  1.,   8.,  27.,  64., 125., 216., 343., 512., 729.]),\n",
       " tensor([0.3333, 0.6667, 1.0000, 1.3333, 1.6667, 2.0000, 2.3333, 2.6667, 3.0000]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binary element by element operations (must be performed with tensors of the same size)\n",
    "C + D, C + D, C**D, C / D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logical operations\n",
    "\n",
    "D > 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D > C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[C > D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2],\n",
       "         [3]]),\n",
       " tensor([[0, 1]]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Broadcasting: handles operations between tensors of different size\n",
    "x = torch.arange(4).reshape(4,1)\n",
    "y = torch.arange(2).reshape(1,2)\n",
    "\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 2],\n",
       "        [2, 3],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + y # x was expanded trought the columns via broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors copies:\n",
    "* Shallow copy;\n",
    "* Deep copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = torch.arange(1,10, dtype=torch.float32)\n",
    "\n",
    "id_before = id(C)\n",
    "C = C + D # Does not reuse memory/creates a new memory space\n",
    "\n",
    "id(C) == id_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = torch.arange(1,10, dtype=torch.float32)\n",
    "\n",
    "id_before = id(C)\n",
    "C[:] = C + D # Reuse memory\n",
    "\n",
    "id(C) == id_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_before = id(C)\n",
    "\n",
    "D = C # Shallow copy: D is a \"view\" of C\n",
    "\n",
    "id(D) == id_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_before = id(C)\n",
    "\n",
    "D = C.clone() # Deep copy: D is a clone of C\n",
    "\n",
    "id(D) == id_before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectors, matrices and array operations\n",
    "\n",
    "* Definition;\n",
    "* Tensor arithmetics;\n",
    "* Reduction;\n",
    "* Dot product;\n",
    "* Matrix, vector operations;\n",
    "* Matrix, matrix operations;\n",
    "* Norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3., 4.], dtype=torch.float64),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 5.,  6.,  7.,  8.,  9.],\n",
       "         [10., 11., 12., 13., 14.],\n",
       "         [15., 16., 17., 18., 19.],\n",
       "         [20., 21., 22., 23., 24.]], dtype=torch.float64))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(5, dtype=torch.float64)\n",
    "A = torch.arange(25, dtype=torch.float64).reshape((5,5))\n",
    "x, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  5., 10., 15., 20.],\n",
       "        [ 1.,  6., 11., 16., 21.],\n",
       "        [ 2.,  7., 12., 17., 22.],\n",
       "        [ 3.,  8., 13., 18., 23.],\n",
       "        [ 4.,  9., 14., 19., 24.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(300., dtype=torch.float64),\n",
       " tensor([ 10.,  35.,  60.,  85., 110.], dtype=torch.float64))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduction: operations that reduce the matrices dimension.\n",
    "A.sum(), A.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 11., 12., 13., 14.], dtype=torch.float64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5.]), tensor([3., 3., 3., 3., 3.]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dot product\n",
    "a = torch.arange(1,6, dtype=torch.float32)\n",
    "b = torch.ones(5)*3\n",
    "a,b\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(45.)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 5.,  6.,  7.,  8.,  9.],\n",
       "         [10., 11., 12., 13., 14.],\n",
       "         [15., 16., 17., 18., 19.],\n",
       "         [20., 21., 22., 23., 24.]], dtype=torch.float64),\n",
       " tensor([0., 1., 2., 3., 4.], dtype=torch.float64),\n",
       " tensor([ 30.,  80., 130., 180., 230.], dtype=torch.float64))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrices operations\n",
    "\n",
    "x = torch.arange(5, dtype=torch.float64)\n",
    "A = torch.arange(25, dtype=torch.float64).reshape((5,5))\n",
    "\n",
    "A, x, torch.mv(A,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 5.,  6.,  7.,  8.,  9.],\n",
       "         [10., 11., 12., 13., 14.],\n",
       "         [15., 16., 17., 18., 19.],\n",
       "         [20., 21., 22., 23., 24.]], dtype=torch.float64),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 5.,  6.,  7.,  8.,  9.],\n",
       "         [10., 11., 12., 13., 14.],\n",
       "         [15., 16., 17., 18., 19.],\n",
       "         [20., 21., 22., 23., 24.]], dtype=torch.float64),\n",
       " tensor([[ 150.,  160.,  170.,  180.,  190.],\n",
       "         [ 400.,  435.,  470.,  505.,  540.],\n",
       "         [ 650.,  710.,  770.,  830.,  890.],\n",
       "         [ 900.,  985., 1070., 1155., 1240.],\n",
       "         [1150., 1260., 1370., 1480., 1590.]], dtype=torch.float64))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, A, torch.mm(A,A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 30.,  80., 130., 180., 230.], dtype=torch.float64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A@x # shrotcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3., 4.], dtype=torch.float64),\n",
       " tensor(5.4772, dtype=torch.float64))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector norm\n",
    "x, torch.norm(x) # euclidean norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.arange(6, dtype=torch.float32).reshape(2, 3)\n",
    "\n",
    "B = torch.ones(3, 2)\n",
    "\n",
    "C = torch.arange(3, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]]),\n",
       " tensor([0., 1., 2.]),\n",
       " tensor([ 5., 14.]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, C, torch.mv(A,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]]),\n",
       " tensor([[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]]),\n",
       " tensor([[ 3.,  3.],\n",
       "         [12., 12.]]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, B, torch.mm(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.,  3.],\n",
       "        [12., 12.]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A@B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.0000,  0.0000],\n",
       "         [ 0.5000, -0.2000],\n",
       "         [ 0.1000,  0.0000]]),\n",
       " tensor([0.5000, 0.5000]),\n",
       " tensor([1., 2., 3.]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.tensor([-1, 0, 0.5, -0.2, 0.1, 0.0], dtype=torch.float32).reshape((3,2))\n",
    "b = torch.tensor([0.5, 0.5], dtype=torch.float32)\n",
    "x = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "\n",
    "w, b, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8000, 0.1000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x@w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_loss(y_hat, y):\n",
    "        l = (y.reshape(y_hat.shape) - y_hat)**2\n",
    "        return l.sum()\n",
    "\n",
    "def cross_entropy(y_hat, y):\n",
    "        l = -y.reshape(y_hat.shape)*np.log(y_hat)\n",
    "        return l.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadratic loss:  tensor(0.6000)\n",
      "Cross entropy:  tensor(1.2040)\n"
     ]
    }
   ],
   "source": [
    "y_hat = torch.tensor([0.2, 0.1, 0.2, 0.1 , 0.1, 0.3], dtype=torch.float32)\n",
    "y = torch.tensor([0, 0, 0, 0, 0, 1], dtype=torch.float32)\n",
    "\n",
    "print('Quadratic loss: ', q_loss(y_hat, y))\n",
    "print('Cross entropy: ', cross_entropy(y_hat, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667]) tensor([0., 0., 0., 0., 0., 1.])\n",
      "Quadratic loss:  tensor(0.8333)\n",
      "Cross entropy:  tensor(1.7918)\n"
     ]
    }
   ],
   "source": [
    "y_hat = torch.tensor([1/6, 1/6, 1/6, 1/6 , 1/6, 1/6], dtype=torch.float32)\n",
    "y = torch.tensor([0, 0, 0, 0, 0, 1], dtype=torch.float32)\n",
    "\n",
    "print(y_hat, y)\n",
    "\n",
    "print('Quadratic loss: ', q_loss(y_hat, y))\n",
    "print('Cross entropy: ', cross_entropy(y_hat, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
